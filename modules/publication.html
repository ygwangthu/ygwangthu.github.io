<!-- publication -->
<article id="publication" class="panel" style="padding:0.5em auto">
    <header>Publications</header> 
    <div style="font-size:0.7em;line-height:2em;padding-left:1em;color:#EB7500;margin-bottom:0.5em;font-weight:bold">
        <i class="fa fa-info-circle"></i> Follow my work on <a target="_blank" href="https://scholar.google.com/citations?hl=en&user=zbJuQMgAAAAJ">Google Scholar</a>
    </div>

    <table>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\tomm-zpyu-cloth\teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>T2C: Text-guided 4D Cloth Generation</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>ACM Transactions on Multimedia Computing, Communications and Applications (<strong>TOMM</strong>), 2025</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em"> Zhipeng Yu, Zimeng Zhao, Yanxi Du, Yuzhou Zheng, Binghui Zuo, and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://dl.acm.org/doi/10.1145/3735642">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="#publication">Webpage (coming soon) <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\tip2025-nphand\teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>NP-Hand: Novel Perspective Hand Image Synthesis Guided by Normals</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Transactions on Image Processing (<strong>TIP</strong>), 2025</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em"> Binghui Zuo, Wenqian Sun, Zimeng Zhao, Xiaohan Yuan, and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://ieeexplore.ieee.org/document/10969541">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers\tip2025-nphand\ZBH-NPHand-2025-04.html">Webpage <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\cvpr2025\teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2025</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Buzhen Huang, Chen Li, Chongyang Xu, Dongyue Lu, Jinnan Chen, <strong>Yangang Wang</strong>, and Gim Hee Lee</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://cvpr.thecvf.com/virtual/2025/poster/32642">Paper <i class="fa fa-arrow-right"></i></a></span></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\tvcg2024-graspdiff\teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>GraspDiff: Grasping Generation for Hand-Object Interaction with Multimodal Guided Diffusion</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Transactions on Visualization and Computer Graphics (<strong>TVCG</strong>), 2024</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em"> Binghui Zuo, Zimeng Zhao, Wenqian Sun, Xiaohan Yuan, Zhipeng Yu, and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://ieeexplore.ieee.org/document/10689328">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers\tvcg2024-graspdiff\ZUO-GraspDiff-2024-09.html">Webpage <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\accv2024\teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>TexDC: Text-Driven Disease-Aware 4D Cardiac Cine MRI Images Generation</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>Asian Conference on Computer Vision (<strong>ACCV</strong>), 2024</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em"> Cong Liu, Xiaohan Yuan, and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://link.springer.com/chapter/10.1007/978-981-96-0901-7_12">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers\accv2024\LIU-TEXDC-2024.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://github.com/me-congliu/TexDC">Code <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

            <!-- paper -->
            <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\jsen2024-handencoding\teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Accurate and Real-time Variant Hand Pose Estimation Based on Gray Code Bounding Box Representation</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Sensors Journal, 2024</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em"> <strong>Yangang Wang</strong>, Wenqian Sun, and Ruting Rao</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://ieeexplore.ieee.org/document/10506333">Paper <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\CVPR2024\teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Closely Interactive Human Reconstruction with Proxemics and Physics-Guided Adaption</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Buzhen Huang, Chen Li, Chongyang Xu, Liang Pan, <strong>Yangang Wang</strong> and Gim Hee Lee</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://openaccess.thecvf.com/content/CVPR2024/papers/Huang_Closely_Interactive_Human_Reconstruction_with_Proxemics_and_Physics-Guided_Adaption_CVPR_2024_paper.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>


        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\spl2024-zhao\teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Music Conditioned Generation for Human-centric Video</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Signal Processing Letters, 2024</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Zimeng Zhao, Binghui Zuo, and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://ieeexplore.ieee.org/document/10415104">Paper <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\3dv2024-interscene\teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Synthesizing Physically Plausible Human Motions in 3D Scenes</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>International Conference on 3D Vision (<strong>3DV</strong>), 2024</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Liang Pan, Jingbo Wang, Buzhen Huang, Junyu Zhang, Haofan Wang, Xu Tang and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://arxiv.org/abs/2308.09036">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://github.com/liangpan99/InterScene">Code <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\ICCV2023\cardiac4d-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>4D Myocardium Reconstruction with Decoupled Motion and Shape Model</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>), 2023</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Xiaohan Yuan, Cong Liu and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://arxiv.org/abs/2308.14083">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers\iccv2023-yxh\YUAN-4DM-2023-07.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://github.com/yuan-xiaohan/4D-Myocardium-Reconstruction-with-Decoupled-Motion-and-Shape-Model">Code <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers\iccv2023-yxh\YUAN-4DM-2023-07.html#dataset">Dataset <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\ICCV2023\groupreconstruction-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Reconstructing Groups of People with Hypergraph Relational Reasoning</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>), 2023</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Buzhen Huang, Jingyi Ju, Zhihao Li and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://arxiv.org/abs/2308.15844">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers\iccv2023-grouprec\HUANG-GROUPREC-2023-07.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers\iccv2023-grouprec\HUANG-GROUPREC-2023-07.html#dataset">Dataset <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\ICCV2023\Interhands-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Reconstructing Interacting Hands with Interaction Prior from Monocular Images</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>), 2023</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Binghui Zuo, Zimeng Zhao, Wenqian Sun, Wei Xie, Zhou Xue and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://arxiv.org/abs/2308.14082">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/iccv2023_interprior/BinghuiZuo-ICCV2023_InterPrior.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://github.com/binghui-z/InterPrior_pytorch">Code <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/iccv2023_interprior/BinghuiZuo-ICCV2023_InterPrior.html#dataset">Dataset <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\ICCV2023\nonrigidcontact-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Nonrigid Object Contact Estimation With Regional Unwrapping Transformer</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>), 2023</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Wei Xie, Zimeng Zhao, Shiying Li, Binghui Zuo and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://arxiv.org/abs/2308.14074">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers\iccv2023-nonrigid\XIE-NONRIGID-2023-07-paper.html">Webpage <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

            <!-- paper -->
            <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\tcsvt2023-multiperson\teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Simultaneously Recovering Multi-Person Meshes and Multi-View Cameras with Human Semantics</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), 2023</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Buzhen Huang, Jingyi Ju, Yuan Shu and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://ieeexplore.ieee.org/document/10299685">Paper <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\IJCAI2023\PGH-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Physics-Guided Human Motion Capture with Pose Probability Modeling</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>International Joint Conferences on Artificial Intelligence (<strong>IJCAI</strong>), 2023</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Jingyi Ju, Buzhen Huang, Chen Zhu, Zhihao Li and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers\IJCAI2023\jyj23_pgh.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://github.com/Me-Ditto/Physics-Guided-Mocap">Code <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers/CVM2023-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span style="display:block;font-size:1.1em;font-weight:bold;padding-bottom:0.2em">HMDO : Markerless Multi-view Hand Manipulation Capture with Deformable Objects</span>
                <span style="display:block;color:#FF1A1A;font-weight:bold;padding-bottom:1.2em">(Public dataset: HMDO, 12 deformable objects, 21600 frames)</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;"><i>International Conference on Computational Visual Media (<strong>CVM</strong>), 2023</i></span>
                <span style="display:block;font-size:0.8em;font-family:Arial;padding-bottom:0.7em"><i>(Recommended publishing on <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S1524070323000085">Graphical Models</a>)</i></span>
                <span style="display:block;font-size:1.1em">Wei Xie*, Zhipeng Yu*, Zimeng Zhao, Binghui Zuo and <strong>Yangang Wang</strong></span>
                <span style="display:block;padding-bottom:1.5em">(*contribute equally)</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://arxiv.org/abs/2301.07652">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/cvm2023-hmdo/XIE-HMDO-2023.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/cvm2023-hmdo/XIE-HMDO-2023.html#dataset">Dataset <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\CVPR2023\SHA-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Semi-supervised Hand Appearance Recovery via Structure Disentanglement and Dual Adversarial Discrimination</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Zimeng Zhao, Binghui Zuo, Zhiyu Long and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/CVPR2023/ZHAO-SHAR-2023-03.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/CVPR2023/ZHAO-SHAR-2023-03.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\ZHAO-TVCG-2023-01-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Skeleton Extraction for Articulated Objects with the Spherical Unwrapping Profiles</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Transactions on Visualization and Computer Graphics (<strong>TVCG</strong>), 2023</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Zimeng Zhao, Wei Xie, Binghui Zuo and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/TVCG2023/ZHAO-SUPPLE-TVCG-2023.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/TVCG2023/ZHAO-SUPPLE-TVCG-2023.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\SliceMask\YUAN-ACCV2022-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span style="display:block;font-size:1.1em;font-weight:bold;padding-bottom:0.2em">Slice-mask based 3D Cardiac Shape Reconstruction from CT Volume</span>
                <span style="display:block;color:#FF1A1A;font-weight:bold;padding-bottom:1.5em">(Public dataset: LV-CT-Healthy)</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>Asian Conference on Computer Vision (<strong>ACCV</strong>), 2022</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Xiaohan Yuan, Cong Liu, Fu Feng, Yinsu Zhu and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/SliceMask/YUAN-ACCV2022-SliceMask.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://github.com/yuan-xiaohan/Slice-mask-based-3D-Cardiac-Shape-Reconstruction">Code <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://drive.google.com/drive/folders/1OxP3ciMpSlgGDOmsOe7To2ZCkg8sv4aE">Dataset <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\HBZ-OOH-2022-08.jpg" loading="lazy"></div></td>
            <td>
                <span>Object-Occluded Human Shape and Pose Estimation with Probabilistic Latent Consistency</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.5em"><i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2022</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:0.2em">Tianshu Zhang*, Buzhen Huang* and <strong>Yangang Wang</strong></span>
                <span style="display:block;padding-bottom:1.5em">(*contribute equally)</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://ieeexplore.ieee.org/document/9858644/">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/ZHANG-OOH-2020-03.html#dataset">Dataset <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\HUANG-PoseUV.jpg" loading="lazy"></div></td>
            <td>
                <span style="display:block;font-size:1.1em;font-weight:bold;padding-bottom:0.2em">Pose2UV: Single-shot Multi-person Mesh Recovery with Deep UV Prior</span>
                <span style="display:block;color:#FF1A1A;font-weight:bold;padding-bottom:1.5em">(Public dataset: 3DMPB)</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Transactions on Image Processing (<strong>TIP</strong>), 2022</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:0.2em">Tianshu Zhang*, Buzhen Huang* and <strong>Yangang Wang</strong></span>
                <span style="display:block;padding-bottom:1.5em">(*contribute equally)</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/HBZ-pose2uv-2022-06.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/HBZ-Pose2UV-2022-06.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://www.bilibili.com/video/BV19t4y1h7vJ">Video <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/HBZ-Pose2UV-2022-06.html#dataset">Dataset <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\SU-DeepCloth.jpg" loading="lazy"></div></td>
            <td>
                <span>DeepCloth: Neural Garment Representation for Shape and Style Editing</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2022</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Zhaoqi Su, Tao Yu, <strong>Yangang Wang</strong> and Yebin Liu</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://ieeexplore.ieee.org/document/9760157">Paper <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\HBZ-NM-2022-03.jpg" loading="lazy"></div></td>
            <td>
                <span>Neural MoCon: Neural Motion Control for Physically Plausible Human Motion Capture</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Buzhen Huang, Liang Pan, Yuan Yang, Jingyi Ju and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/HBZ-NM-2022-03.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/HBZ-NM-2022-03.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://www.bilibili.com/video/BV1W94y1f7ht">Video <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\ZZM-SCR-2022-03.jpg" loading="lazy"></div></td>
            <td>
                <span style="display:block;font-size:1.1em;font-weight:bold;padding-bottom:0.2em">Stability-driven Contact Reconstruction From Monocular Color Images</span>
                <span style="display:block;color:#FF1A1A;font-weight:bold;padding-bottom:1.5em">(Public dataset: 20 subjects, 25 calibrated views)</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Zimeng Zhao, Binghui Zuo, Wei Xie and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/ZZM-SCR-2022-03.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/ZZM-SCR-2022-03.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://www.bilibili.com/video/BV1w3411u7Qp">Video <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/ZZM-SCR-2022-03.html#dataset">Dataset <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\ZHAO-3DV2021-10-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>SUPPLE: Extracting Hand Skeleton with Spherical Unwrapping Profiles</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>International Conference on 3D Vision (<strong>3DV</strong>), 2021</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Zimeng Zhao, Ruting Rao and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/ZHAO-3DV2021-10.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/ZHAO-3DV-2021-10-poster.pdf">Poster <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\HUANG-3DV-2021-10-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Dynamic Multi-person Mesh Recovery from Uncalibrated Multi-view Cameras</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>International Conference on 3D Vision (<strong>3DV</strong>), 2021</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Buzhen Huang, Yuan Shu, Tianshu Zhang and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/HUANG-3DV-2021-10.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://www.bilibili.com/video/BV1Qq4y1d78S">Video <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://github.com/boycehbz/DMMR">Code <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/HUANG-3DV-2021-10-poster.pdf">Poster <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\ZHAO-ICCV2021-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>TravelNet: Self-supervised Physically Plausible Hand Motion Learning from Monocular Color Images</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>), 2021</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Zimeng Zhao, Xi Zhao and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/ZHAO-TRAVEL-2021-08.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://www.bilibili.com/video/BV1FQ4y1y7yz/">Video <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://pan.seu.edu.cn:443/link/D9A5C91028110ADD66A0C5C9AE1F35BD">Dataset <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\BAOWEN-ICCV2021-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Interacting Two-Hand 3D Pose and Shape Reconstruction from Single Color Image</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>), 2021</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Baowen Zhang, <strong>Yangang Wang</strong>, Xiaoming Deng, Yinda Zhang, Ping Tan, Cuixia Ma and Hongan Wang</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/ZHANG-ITH-2021-08.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://github.com/BaowenZ/Intershape">Code <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\ZHUANG-MTD-2021-09.jpg" loading="lazy"></div></td>
            <td>
                <span>Music2Dance: DanceNet for Music-driven Dance Generation</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.5em"><i>ACM Transactions on Multimedia Computing, Communications and Applications (<strong>TOMM</strong>), 2021</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Wenlin Zhuang, Congyi Wang, Siyu Xia, Jinxiang Chai, and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://arxiv.org/pdf/2002.03761.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://www.bilibili.com/video/BV1z3411q7EU/">Video <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\WANG-PHM-2020-08-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span>Personalized Hand Modeling from Multiple Postures with
                    Multi-view Color images</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>Computer Graphics Forum (<strong>Pacific Graphics</strong>), 2020</i> </span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em"><strong>Yangang Wang</strong>, Ruting Rao and Changqing Zou</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/WANG-PHM-2020-11.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://pan.seu.edu.cn:443/link/EC4A13655470FBAE2976C0F137F1007E">Dataset <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 174;" data-src="papers\HUANG-OOH-2020-02-teaser.jpg" loading="lazy"></div></td>
            <td>
                <span style="display:block;font-size:1.1em;font-weight:bold;padding-bottom:0.2em">Object-Occluded Human Shape and Pose Estimation from a Single Color Image</span>
                <span style="display:block;color:#FF1A1A;font-weight:bold;padding-bottom:1.5em">(Oral presentation)</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i> IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2020</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:0.2em">Tianshu Zhang*, Buzhen Huang* and <strong>Yangang Wang</strong></span>
                <span style="display:block;padding-bottom:1.5em">(*contribute equally)</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/ZHANG-OOH-2020-03.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/ZHANG-OOH-2020-03.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://gitee.com/seuvcl/CVPR2020-OOH">Code <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/ZHANG-OOH-2020-03.html#dataset">Dataset <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 179;" data-src="papers\ZHAO-H3D-2020-02.jpg" loading="lazy"></div></td>
            <td>
                <span style="display:block;font-size:1.1em;font-weight:bold;padding-bottom:0.2em">Hand-3D-Studio: A New Multi-view System for 3D Hand Reconstruction</span>
                <span style="display:block;color:#FF1A1A;font-weight:bold;padding-bottom:1.5em">(Public dataset: 200+ hand 3D meshes, 20K RGB images, 15 calibrated views)</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i> International Conference on Acoustics, Speech, and Signal Processing (<strong>ICASSP</strong>), 2020</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Zhengyi Zhao, Tianyao Wang, Siyu Xia and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/icassp2020-hand3dstudio/ZHAO-H3D-2020-02.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/icassp2020-hand3dstudio/ZHAO-H3S-2020-02.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/icassp2020-hand3dstudio/ZHAO-H3S-2020-02.html#dataset">Dataset <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 163;" data-src="papers\WANG-SRH-2019-11.png" loading="lazy"></div></td>
            <td>
                <span>SRHandNet: Real-time 2D Hand Pose Estimation with Simultaneous Region Localization</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Transactions on Image Processing (<strong>TIP</strong>), 2019</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em"><strong>Yangang Wang</strong>, Baowen Zhang and Cong Peng</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/WANG-SRH-2019-11.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/WANG-SRH-2019-07.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/WANG-SRH-2019-07.html#code">Code <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 179;" data-src="papers\WANG-MCC-2018-10.png" loading="lazy"></div></td>
            <td>
                <span style="display:block;font-size:1.1em;font-weight:bold;padding-bottom:0.2em">Mask-pose Cascaded CNN for 2D Hand Pose Estimation from Single Color Image</span>
                <span style="display:block;color:#FF1A1A;font-weight:bold;padding-bottom:1.5em">(Public dataset: OneHand10K)</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), 2019</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em"><strong>Yangang Wang</strong>, Cong Peng and Yebin Liu </span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/WANG-MCC-2018-10.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/WANG-MCC-2018-10.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/WANG-MCC-2018-10.html#code">Code <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/WANG-MCC-2018-10.html#dataset">Dataset <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy" width="100%" style="max-height: 119;" data-src="papers/PENG-PNV-2019-11.jpg" loading="lazy"></div></td>
            <td>
                <span>Phase-Based Non-Contact Vibration Measurement for High Speed Magnetically Suspended Rotor</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Transactions on Instrumentation and Measurement (<strong>TIM</strong>), 2019</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Cong Peng, Cong Zeng and <strong>Yangang Wang</strong> </span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/PENG-PNV-2019-11.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 130;" data-src="papers\PENG-CMM-2019-10.jpg" loading="lazy"></div></td>
            <td>
                <span>Camera-based Micro-vibration Measurement for Lightweight Structure using an Improved Phase-based Motion Extraction</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Sensors Journal, 2019</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Cong Peng, Cong Zeng and <strong>Yangang Wang</strong> </span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/PENG-CMM-2019-10.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 130;" data-src="papers\Zhuang-MAS-2018-09.jpg" loading="lazy"></div></td>
            <td>
                <span>Multi-scale Adaptive Structure Network for Human Pose Estimation from Color Images</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>Asian Conference on Computer Vision (<strong>ACCV</strong>), 2018</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Wenlin Zhuang, Cong Peng, Siyu Xia and <strong>Yangang Wang</strong></span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/ZHUANG-MAS-2018-10.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 174;" data-src="papers\LI-SPE-2018-08.png" loading="lazy"></div></td>
            <td>
                <span>Shape and Pose Estimation for Closely Interacting Persons Using Multi-view Images</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>Computer Graphics Forum (<strong>Pacific Graphics</strong>), 2018</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em">Kun Li, Nianhong Jiao, Yebin Liu, <strong>Yangang Wang</strong> and Jingyu Yang</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/LI-SPE-2018-08.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 154;" data-src="papers\WANG-OMM-2017-04.jpg" loading="lazy"></div></td>
            <td>
                <span>Outdoor Markerless Motion Capture with Sparse Handheld Video Cameras</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Transactions on Visualization and Computer Graphics (<strong>TVCG</strong>), 2018</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1.5em"><strong>Yangang Wang</strong>, Yebin Liu, Xin Tong, Qionghai Dai and Ping Tan</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/WANG-OMM-2017-04.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/WANG-OMM-2017-04.html">Webpage <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 202;" data-src="papers\GUO-RNR-2017-04.jpg" loading="lazy"></div></td>
            <td>
                <span>Robust Non-Rigid Motion Tracking and Surface Reconstruction Using L0 Regularization</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Transactions on Visualization and Computer Graphics (<strong>TVCG</strong>), 2018</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1em;padding-bottom:1.5em">KaiWen Guo, Feng Xu, <strong>Yangang Wang</strong>, Yebin Liu and Qionghai Dai</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/7888591">Paper <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 108;" data-src="papers\QIN-DEP-2017-04.jpg" loading="lazy"></div></td>
            <td>
                <span>Depth Estimation by Parameter Transfer With a Lightweight Model for Single Still Images</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), 2017</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1em;padding-bottom:1.5em">Hongwei Qin, Xiu Li, <strong>Yangang Wang</strong>, Yongbing Zhang and Qionghai Dai</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/QIN-DEP-2017-04.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 99;" data-src="papers\WANG-NFP-2016-05.jpg" loading="lazy"></div></td>
            <td>
                <span>Normalized Filter Pool for Prior Modeling of Nature Images</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>Machine Vision and Applications, 2016</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1em;padding-bottom:1.5em"><strong>Yangang Wang</strong>, Jinli Suo and Qionghai Dai</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/WANG-NFP-2016-05.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 159;" data-src="papers\GUO-RNR-2015-11.jpg" loading="lazy"></div></td>
            <td>
                <span>Robust Non-Rigid Motion Tracking and Surface Reconstruction Using L0 Regularization</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE International Conference on Computer Vision (<strong>ICCV</strong>), 2015</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1em;padding-bottom:1.5em">KaiWen Guo, Feng Xu, <strong>Yangang Wang</strong>, Yebin Liu and Qionghai Dai</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://openaccess.thecvf.com/content_iccv_2015/papers/Guo_Robust_Non-Rigid_Motion_ICCV_2015_paper.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 130;" data-src="papers\LI-DDE-2014-07.jpg" loading="lazy"></div></td>
            <td>
                <span>DEPT: Depth Estimation by Parameter Transfer for Single Still Images</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>Asian Conference on Computer Vision (<strong>ACCV</strong>), 2014</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1em;padding-bottom:1.5em">Xiu Li, HongWei Qin, <strong>Yangang Wang</strong>, Yongbing Zhang and Qionghai Dai</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/LI-DDE-2014-07.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 167;" data-src="papers\LIU-HPC-2014-07.jpg" loading="lazy"></div></td>
            <td>
                <span>Human Performance Capture Using Multiple Handheld Kinects</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i><strong>Book Chapter:</strong> Computer Vision and Machine Learning with RGB-D Sensors, 2014</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1em;padding-bottom:1.5em">Yebin Liu, Genzhi Ye, <strong>Yangang Wang</strong>, Qionghai Dai and Christian Theobalt</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/LIU-HPC-2014-07.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 115;" data-src="papers\WANG-APM-2014-07.jpg" loading="lazy"></div></td>
            <td>
                <span>A Parametric Model for Describing the Correlation Between Single Color Images and Depth Maps</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>IEEE Signal Processing Letters, 2014</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1em;padding-bottom:1.5em"><strong>Yangang Wang</strong>, Ruiping Wang and Qionghai Dai</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/WANG-APM-2014-07.pdf">Paper <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 97;" data-src="papers\SOFIEN-OMR-2013-07.jpg" loading="lazy"></div></td>
            <td>
                <span>Online Modeling for Realtime Facial Animation</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>ACM Transactions on Graphics (<strong>SIGGRAPH</strong>), 2013</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1em;padding-bottom:1.5em">Sofien Bouaziz, <strong>Yangang Wang</strong> and Mark Pauly</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://dl.acm.org/doi/10.1145/2461912.2461976">Paper <i class="fa fa-arrow-right"></i></a></span>
            </td>
        </tr>

        <!-- paper -->
        <tr>
            <td><div class="image_carousel"><img class="lazy"  width="100%" style="max-height: 176;" data-src="papers\WANG-VHM-2013-07.jpg" loading="lazy"></div></td>
            <td>
                <span>Video-based Hand Manipulation Capture Through Composite Motion Control</span>
                <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.4em"><i>ACM Transactions on Graphics (<strong>SIGGRAPH</strong>), 2013</i></span>
                <span style="display:block;font-size:1.1em;padding-bottom:1em;padding-bottom:1.5em"><strong>Yangang Wang</strong>, Jianyuan Min, Jianjie Zhang, Yebin Liu, Feng Xu, Qionghai Dai and Jinxiang Chai</span>
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="https://dl.acm.org/doi/10.1145/2461912.2462000">Paper <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
                <span style="font-size:0.9em;padding-bottom:0.5em"><a target="_blank" href="papers/WANG-VHM-2013.html">Webpage <i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp
            </td>
        </tr>
    </table>
    <hr style="height:1px;border:none;border-top:1px solid #dedddd;margin-top:1em"/>
    <header>Ph.D. Thesis</header> <span style="display:inline-block;font-size:0.7em">(in Chinese)</span>
    <table style="border-collapse:separate;width:100%;border:none;margin-bottom: 0em;">
    <!-- paper -->
    <tr style="height:8em;width:100%;font-size:0.7em;line-height:1.2em;">
        <td style="width:30%;vertical-align:top;padding-left:0.5em;padding-top:1em;padding-bottom:0em;text-align:center"><img class="lazy" width="52%" style="max-height: 140;" data-src="images\tsinghua_logo.jpg" loading="lazy"></td>
        <td>
            <span style="display:block;font-size:1.1em;font-weight:bold;padding-top:0.5em;padding-bottom:1.5em">Markerless Motion Capture and Motion Retargeting</span>
            <span style="display:block;font-size:1.0em;font-family:Arial;padding-bottom:0.5em">Department of Automation, Tsinghua University, July 2014</span>
            <span style="display:block;font-size:1.1em;padding-bottom:1.5em;font-weight:bold">Yangang Wang</span>
        </td>
    </tr>
    </table>
</article>