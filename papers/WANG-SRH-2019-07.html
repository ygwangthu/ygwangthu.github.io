<!DOCTYPE HTML>
<html>
<head>
	<title>SRHandNet: Real-time 2D Hand Pose Estimation with Simultaneous Region Localization</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,Chrome=1" />
    <!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
	<link rel="icon" href="../images/logo.ico" />
    <link rel="stylesheet" href="../assets/css/main.css" />
    
    <!-- Scripts -->
    <script src="../assets/js/jquery.min.js"></script>
    <script src="../assets/js/jquery.lazy.min.js"></script>
</head>

<body class="is-preload">
    <div id="wrapper">
        <div id="main" class="panel" style="margin-top:2em;line-height:1.3em">
            <article id="news" class="panel">
                <!-- head -->
                <div style="font-size:0.75em;text-align:center;padding-top:0.5em">IEEE Transactions on Image Processing (TIP)</div>
                <div style="font-size:1.0em;font-weight:bold;padding:1em 0.5em;text-align:center">SRHandNet: Real-time 2D Hand Pose Estimation with Simultaneous Region Localization</div>
                <div style="font-size:0.75em;padding-bottom:1em;text-align:center">
                    <div style="display:inline-block;"><a target="_blank" href="http://yangangwang.com/" style="color:#EB7500">Yangang Wang</a><sup>1</sup>, </div>&nbsp;&nbsp;
                    <div style="display:inline-block;">Baowen Zhang<sup>1</sup>, </div>&nbsp;&nbsp;
                    <div style="display:inline-block;">Cong Peng<sup>2</sup></div>              
                </div>
                <div style="font-size:0.75em;padding-bottom:1em;text-align:center">
                    <div style="display:inline-block;"><sup>1</sup><a target="_blank" href="http://www.seu.edu.cn/english/main.htm" style="font-weight:bold">Southeast University</a></div>&nbsp;&nbsp;
                    <div style="display:inline-block;"><sup>2</sup><a target="_blank" href="http://www.nuaa.edu.cn/" style="font-weight:bold">Nanjing University of Aeronautics and Astronautics</a></div>
                </div>
                <hr style="height:1px;border:none;border-top:1px solid #dedddd;;margin-bottom:1em"/>

                <!-- teaser -->
                <div style="text-align:center;"><img class="lazy" width="100%" data-src="WANG-SRH-2019-07-teaser.png"></div>
                <div style="text-align:left;font-size:0.75em;line-height:1.4em"><div style="font-weight:bold;display:inline-block">Overview of SRHandNet.</div> We use an encoder-decoder architecture as the backbone of our network to perform the 2D hand pose estimation. In the training stage, the intermediate supervision is adopted. In the inference stage, we perform the cycle detection according to the size of hand. </div>

                <!-- abstract -->
                <div style="font-size:0.9em;font-weight:bold;padding-top:2em;">Abstract</div>
                <hr style="height:1px;border:none;border-top:1px solid #dedddd;margin-bottom:1em"/>
                <div style="text-align:left;font-size:0.75em;line-height:1.4em">This paper introduces a novel method for real-time 2D hand pose estimation from monocular color images, which is named as <div style="font-weight:bold;display:inline-block">SRHandNet</div>. Existing methods can not time efficiently obtain appropriate results for small hand. Our key idea is to regress the hand region of interests (RoIs) and hand keypoints simultaneously for a given color image, and iteratively take the hand RoIs as feedback information for boosting the performance of hand keypoints estimation with a single encoder-decoder network architecture. Different from previous region proposal network (RPN), a new lightweight bounding box representation, which is called <div style="font-weight:bold;display:inline-block">region map</div>, is proposed. The proposed bounding box representation map together with hand keypoints heatmaps are combined into a unified multi-channel feature map, which can be easily acquired with only one forward network inference and thus improve the runtime efficiency of the network. SRHandNet can run at 40fps for hand bounding box detection and up to 30fps accurate hand keypoints estimation under the desktop environment without implementation optimization. Experiments demonstrate the effectiveness of the proposed method. State-of-the-art results are also achieved out competing all recent methods.</div>

                <!-- Code -->
                <div style="font-size:0.9em;font-weight:bold;padding-top:2em">Running Code and Trained Model</div>
                <hr style="height:1px;border:none;border-top:1px solid #dedddd;margin-bottom:1em"/>
                <div style="font-size:0.75em;text-align:left;line-height:1.4em;">
                    Here, we release the demo code (under <a target="_blank" href="https://visualstudio.microsoft.com/">VS2019</a>, Nvidia 1080Ti with <a target="_blank" href="https://developer.nvidia.com/cuda-downloads">CUDA10.1</a> and <a target="_blank" href="https://developer.nvidia.com/cudnn">cuDNN7.6</a>, Win10). You can directly run the code with the given model [hand.pts] and deploy it into real desktop applications. <div style="font-weight:bold;display:inline-block">[Note: if you use other Graphic cards, please re-compile the source code]</div>
                    <p>
                        <span style="font-size:0.9em;"><a target="_blank" href="https://seueducn1-my.sharepoint.com/:f:/g/personal/yangangwang_seu_edu_cn/EtpBuP9CH-lOs_mqqECVGcgB31jEZNFcunPZUfyK9GBgUw?e=OIMYDq">Demo Example Code (windows version) <i class="fa fa-arrow-right"></i></a></span>
                    </p>
                    We also release the source code for your personal compilation under other platforms. The rights to copy, distribute, and use the code are being given access to are under the control of Yangang Wang, director of the Vision and Cognition Lab, Southeast University. In this case, credit must be given to: *SRHandNet: Real-time 2D Hand Pose Estimation with Simultaneous Region Localization*. <div style="font-weight:bold;display:inline-block">Any commercial use is not allowed</div>. Node that this code relies on the C++ library of Pytorch and OpenCV. You should configure Pytorch and OpenCV correctly beforehand. I am very glad to receive your feedbacks about this code. 
                    <p>
                        <span style="font-size:0.9em;"><a target="_blank" href="WANG-SRH-2019-07-code/demo_source_code.cpp">Source Code <i class="fa fa-arrow-right"></i></a></span>
                    </p>

                    It is noted that our network was originally trained by Caffe2. Since Caffe2 has been integrated into <a href="https://pytorch.org/">Pytorch</a>, we both release the trained models with Pytorch and Caffe2 (<div style="font-weight:bold;display:inline-block">We strongly recommend you to use the Pytorch model</div>) cause Pytorch has a more active community <i class="fa fa-smile-o"></i>.
                    <p>
                        <span style="font-size:0.9em;"><a target="_blank" href="https://seueducn1-my.sharepoint.com/:f:/g/personal/yangangwang_seu_edu_cn/Eo96bU-gpE9Fl0zbdENnARIB0ni1j-CplZAerfEeM-R_aw?e=TA3rVr">Model trained by Pytorch<i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp&nbsp&nbsp
                        <span style="font-size:0.9em;"><a target="_blank" href="https://seueducn1-my.sharepoint.com/:f:/g/personal/yangangwang_seu_edu_cn/ErRN1lmAAW5FtLuGb4VIA_0Bwb-opRZPdsslUFrdDvvITA?e=CFpzkK">Model trained by Caffe2<i class="fa fa-arrow-right"></i></a></span>&nbsp&nbsp&nbsp&nbsp
                    </p>

                   We use the training dataset from our public dataset <a target="_blank" href="WANG-MCC-2018-10.html">OneHand10K</a>. If you want to retrain the model by your own, you can send me E-mail to request the dataset by the necessary requirements. Moreover, the evaluation dataset in this paper can be downloaded in the following link. 
                    <p>
                        <span style="font-size:0.9em;"><a target="_blank" href="https://seueducn1-my.sharepoint.com/:f:/g/personal/yangangwang_seu_edu_cn/EuxOMkHS2aBDrBAmMLK-z2ABrEo71dKzwe_YvBwX6UVnLA?e=1as4jh">Evaluation Dataset <i class="fa fa-arrow-right"></i></a></span>
                    </p>
                </div>

                <!-- results -->
                <div style="font-size:0.9em;font-weight:bold;padding-top:2em">Results</div>
                <hr style="height:1px;border:none;border-top:1px solid #dedddd;margin-bottom:1em"/>
                <div style="text-align:center"><img class="lazy" width="100%" src="WANG-SRH-2019-07-result.png"></div>

                <!-- materials -->
                <div style="font-size:0.9em;font-weight:bold;padding-top:2em">Materials</div>
                <hr style="height:1px;border:none;border-top:1px solid #dedddd;margin-bottom:1em"/>
                <table>
                    <tr>
                        <td style="width:25%;padding:0em 0.5em;border-right:1px solid #dedddd">
                            <a target="_blank" href="" title="paper"><div class="image_carousel"><img class="lazy" width="100%" data-src="WANG-SRH-2019-07-paper.png"></div></a>
                            <hr style="height:1px;border:none;border-top:1px solid #dedddd;" />
                            <div style="font-size:0.7em;text-align:left;line-height:1.4em">Related links</div>
                            <ul style="font-size:0.6em;line-height:1.4em;margin-top:0em;">
                                <li><a target="_blank" href="WANG-SRH-2019-11.pdf">Download Paper</a></li>
                                <li><a target="_blank" href="WANG-SRH-2019-11.bib">Download Bibtex</a></li>
                                <li><a target="_blank" href="https://doi.org/10.1109/TIP.2019.2955280">IEEE Digital Library</a></li>
                                <li><a target="_blank" href="https://youtu.be/YdsajJ8sxqg">Video on YouTube</a></li>
                            </ul>
                        </td>
                        <td style="width:75%;padding:0em 0.3em">
                            <div class="video-container">
                                <iframe id="hand2d" src="" width="1280" height="720" frameborder="0" allowfullscreen></iframe>
                            </div>
                        </td>
                    </tr>
                </table>

                <!-- Reference -->
                <div style="font-size:0.9em;font-weight:bold;padding-top:1em">Reference</div>
                <hr style="height:1px;border:none;border-top:1px solid #dedddd;margin-bottom:1em"/>
                <div style="background-color:#ddd;margin-bottom:1em">
                    <div style="text-align:left;font-size:0.75em;line-height:1.4em;padding:1em 1em">Yangang Wang, Baowen Zhang and Cong Peng. "<strong>SRHandNet: Real-time 2D Hand Pose Estimation with Simultaneous Region Localization</strong>". <i>IEEE Transactions on Image Processing</i>, 29(1):2977 - 2986, 2020.</div>
                </div>

                <!-- acknowledgements -->
                <div style="font-size:0.75em;text-align:left;line-height:1.4em"><strong>Acknowledgments:</strong> This work was supported by the National Natural Science Foundation of China (No. 61806054, 6170320), Natural Science Foundation of Jiangsu Province (No. BK20180355 and BK20170812) and Foundation of Southeast University (No. 3208008410 and 1108007121).</div>
            </article>
        </div>

        <!-- Footer -->
		<div id="footer">
            <ul style="list-style: none;"> 
                <li>&copy; 2019 Dr. <a href="../index.html" style="color:#EB7500;text-decoration:none;">Yangang Wang</a>. All Rights Reserved. </li>
                <li><div style="display: flex;justify-content: center;align-items: center;"><img src="../images/beian.png">&nbsp;<a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32011502011122" style="color:rgba(255, 255, 255, 0.45);text-decoration:none;">苏公网安备 32011502011122号</a>&nbsp;&nbsp;&nbsp;<a target="_blank" href="http://www.beian.miit.gov.cn/" style="color:rgba(255, 255, 255, 0.45);text-decoration:none;">京ICP备20006779号</a></div></li>
            </ul>
		</div>
    </div>

    <script src="../assets/js/main.js"></script>
    <script>
		$(function() {
			$('.lazy').Lazy({
                effect : "fadeIn"
            });
		});
	</script>
    <script>setTimeout(function(){document.getElementById('hand2d').src = 'https://www.youtube.com/embed/YdsajJ8sxqg';},50)</script>
</body>
</html>