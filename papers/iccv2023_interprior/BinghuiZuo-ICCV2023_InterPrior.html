<!DOCTYPE HTML>
<html>
<head>
	<title>Reconstructing Interacting Hands with Interaction Prior from Monocular Images</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,Chrome=1" />
    <!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
	<link rel="icon" href="../../assets/images/logo.ico" />
    <link rel="stylesheet" href="../../assets/css/main.css" />
    
    <!-- Scripts -->
    <script src="../../assets/js/jquery.min.js"></script>
    <script src="../../assets/js/jquery.lazy.min.js"></script>
</head>

<body class="is-preload">
    <div id="wrapper">
        <div id="main" class="panel" style="margin-top:2em;line-height:1.3em">
            <article id="news" class="panel">
                <!-- head -->
                <div style="font-size:0.75em;text-align:center;padding-top:0.5em">IEEE/CVF International Conference on Computer Vision (ICCV), 2023</div>
                <div style="font-size:1.0em;font-weight:bold;padding:1em 0.5em;text-align:center">Reconstructing Interacting Hands with Interaction Prior from Monocular Images</div>
                <div style="font-size:0.75em;padding-bottom:1em;text-align:center">
                    <div style="display:inline-block;"><a target="_blank" href="https://binghui-z.github.io/">Binghui Zuo</a><sup>1</sup>, </div>&nbsp;&nbsp;
                    <div style="display:inline-block;"><a target="_blank" href="https://tneitap.github.io/">Zimeng Zhao</a><sup>1</sup>, </div>&nbsp;&nbsp;
                    <div style="display:inline-block;">Wenqian Sun<sup>1</sup>, </div>&nbsp;&nbsp;
                    <div style="display:inline-block;">Wei Xie<sup>1</sup>, </div>&nbsp;&nbsp;
                    <div style="display:inline-block;">Zhou Xue<sup>2</sup>, </div>&nbsp;&nbsp;
                    <div style="display:inline-block;"><a target="_blank" href="http://yangangwang.com/">Yangang Wang</a><sup>1</sup>, </div>&nbsp;&nbsp;
                </div>
                <div style="font-size:0.75em;padding-bottom:1em;text-align:center">
                    <div style="display:inline-block;"><sup>1</sup><a target="_blank" href="http://www.seu.edu.cn/english/main.htm" style="font-weight:bold">Southeast University</a></div>&nbsp;&nbsp;
                    <div style="display:inline-block;"><sup>2</sup><a target="_blank" href="https://www.bytedance.com/zh/" style="font-weight:bold">Pico IDL, ByteDance</a></div>
                </div>
                <hr style="height:1px;border:none;border-top:1px solid #dedddd;;margin-bottom:1em"/>

                <!-- teaser -->
                <div style="text-align:center;"><img class="lazy" width="100%" data-src="ZBH-InterPrior-pipeline.png"></div>
                <div style="text-align:left;font-size:0.75em;line-height:1.4em"><div style="font-weight:bold;display:inline-block">Overview of architecture.</div> The total pipeline consists of three stages. (a) We first design an expressive feature extraction module to extract global and local context information. Besides that, the proposed IAH adaptively maps adjacent joints with Laplacian distribution and provides more visual attention. (b) A ViT-based fusion module is designed to fuse the extracted features, which are regarded as sampling conditions to reconstruct the final result. (c) We build a powerful interaction prior with multimodal datasets and use the physics engine to make the ground truth more physically plausible </div>

                <!-- abstract -->
                <div style="font-size:0.9em;font-weight:bold;padding-top:2em;">Abstract</div>
                <hr style="height:1px;border:none;border-top:1px solid #dedddd;margin-bottom:1em"/>
                <div style="text-align:left;font-size:0.75em;line-height:1.4em">Reconstructing interacting hands from monocular images is indispensable in AR/VR applications. Most existing solutions rely on the accurate localization of each skeleton joint. However, these methods tend to be unreliable due to the severe occlusion and confusing similarity among adjacent hand parts. This also defies human perception because humans can quickly imitate an interaction pattern without localizing all joints. Our key idea is to first construct a two-hand interaction prior and recast the interaction reconstruction task as the conditional sampling from the prior. To expand more interaction states, a large-scale multimodal dataset with physical plausibility is proposed. Then a VAE is trained to further condense these interaction patterns as latent codes in a prior distribution. When looking for image cues that contribute to interaction prior sampling, we propose the interaction adjacency heatmap (IAH). Compared with a joint-wise heatmap for localization, IAH assigns denser visible features to those invisible joints. Compared with an all-in-one visible heatmap, it provides more fine-grained local interaction information in each interaction region. Finally, the correlations between the extracted features and corresponding interaction codes are linked by the ViT module. Comprehensive evaluations on benchmark datasets have verified the effectiveness of this framework.</div>

                <!-- results -->
                <div style="font-size:0.9em;font-weight:bold;padding-top:2em">Results</div>
                <hr style="height:1px;border:none;border-top:1px solid #dedddd;margin-bottom:1em"/>
                <div style="text-align:center"><img class="lazy" width="100%" src="ZBH-InterPrior-result.png"></div>
                <div style="font-size:0.75em;text-align:center;line-height:1.4em;">
                    More reconstruction results on Interhand2.6M dataset.
                </div>

                <!-- materials -->
                <div style="font-size:0.9em;font-weight:bold;padding-top:2em">Materials</div>
                <hr style="height:1px;border:none;border-top:1px solid #dedddd;margin-bottom:1em"/>
                <table>
                    <tr>
                        <td style="width:25%;padding:0em 0.5em;border-right:1px solid #dedddd">
                            <a target="_blank" href="" title="paper"><div class="image_carousel"><img class="lazy" width="100%" data-src="ZBH-InterPrior-page1.png"></div></a>
                            <hr style="height:1px;border:none;border-top:1px solid #dedddd;" />
                            <div style="font-size:0.7em;text-align:left;line-height:1.4em">Related links</div>
                            <ul style="font-size:0.6em;line-height:1.4em;margin-top:0em;">
                                <li><a target="_blank" href="https://arxiv.org/abs/2308.14082">Download Paper</a></li>
                                <li><a target="_blank" href="ZBH-InterPrior-paper-supp.pdf">Download Supplementary</a></li>
                                <li><a target="_blank" href="ZBH-InterPrior.bib">Download Bibtex</a></li>
                                <!-- <li><a target="_blank" href="ZBH-InterPrior-paper-supp.pdf">Download Dateset</a></li> -->
                            </ul>
                        </td>
                        <td style="width:75%;padding:0em 0.3em">
                            <div class="video-container">
                                <iframe id="interprior" src="" width="1280" height="720" frameborder="0" allowfullscreen></iframe>
                            </div>
                        </td>
                    </tr>
                </table>

                <!-- Reference -->
                <div style="font-size:0.9em;font-weight:bold;padding-top:1em">Reference</div>
                <hr style="height:1px;border:none;border-top:1px solid #dedddd;margin-bottom:1em"/>
                <div style="background-color:#ddd;margin-bottom:1em">
                    <div style="text-align:left;font-size:0.75em;line-height:1.4em;padding:1em 1em">Binghui Zuo, Zimeng Zhao, Wenqian Sun, Wei Xie, Zhou Xue and Yangang Wang. "<strong>Reconstructing Interacting Hands with Interaction Prior from Monocular Images</strong>". <i>IEEE/CVF International Conference on Computer Vision (ICCV), 2023.</i></div>
                </div>

                <!-- acknowledgements -->
                <div style="font-size:0.75em;text-align:left;line-height:1.4em"><strong>Acknowledgments:</strong> This work was supported in part by the National Natural Science Foundation of China (No. 62076061), in part by the Natural Science Foundation of Jiangsu Province (No. BK20220127).</div>
            </article>
        </div>

        <!-- Footer -->
		<div id="footer">
            <ul style="list-style: none;"> 
                <li>&copy; 2019 Dr. <a href="../../index.html" style="color:#EB7500;text-decoration:none;">Yangang Wang</a>. All Rights Reserved. </li>
                <li><div style="display: flex;justify-content: center;align-items: center;"><img src="../../assets/images/beian.png">&nbsp;<a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32011502011122" style="color:rgba(255, 255, 255, 0.45);text-decoration:none;">苏公网安备 32011502011122号</a>&nbsp;&nbsp;&nbsp;<a target="_blank" href="http://www.beian.miit.gov.cn/" style="color:rgba(255, 255, 255, 0.45);text-decoration:none;">京ICP备20006779号</a></div></li>
            </ul>
		</div>
    </div>

    <script src="../../assets/js/main.js"></script>
    <script>
		$(function() {
			$('.lazy').Lazy({
                effect : "fadeIn"
            });
		});
	</script>
    <script>setTimeout(function(){document.getElementById('interprior').src = 'https://player.bilibili.com/player.html?bvid=BV1xu411N7dQ&page=1';},50)</script>
</body>
</html>